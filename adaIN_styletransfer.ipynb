{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style transfer with AdaIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "import util.util_validation as ut_val\n",
    "from networks.resnet_big import SupCEResNet, SupConResNet, LinearClassifier, model_dict\n",
    "\n",
    "seaborn.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 0\n",
    "\n",
    "dataset = \"animals10_diff_-1\"\n",
    "styles_path = \"./datasets/adaIN/textures_animals10\"\n",
    "output_path = \"./datasets/adaIN/shape_texture_conflict_animals10\"\n",
    "\n",
    "\n",
    "tmp_shape = \"./datasets/adaIN/tmp/shape/\"\n",
    "tmp_style = \"./datasets/adaIN/tmp/style/\"\n",
    "\n",
    "adaIn_venv_interpreter = \"./../adain_venv/bin/python\"\n",
    "addIn_path = \"./../pytorch-AdaIN/\"\n",
    "\n",
    "adaIn_execution_file = os.path.join(addIn_path, \"test.py\")\n",
    "adaIn_vgg = os.path.join(addIn_path, \"models/vgg_normalised.pth\")\n",
    "adaIn_decoder = os.path.join(addIn_path, \"models/decoder.pth\")\n",
    "\n",
    "classes = ut_val.get_classes(dataset)\n",
    "_, root_test = ut_val.get_root_dataset(dataset)\n",
    "\n",
    "image_loader = datasets.folder.default_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_files_dataFrame(root, classes):\n",
    "    \"\"\"\n",
    "    Creates a pandas DataFrame for a image dataset of the form ./root/class/img.png\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root: str\n",
    "        The path to the dataset\n",
    "    classes: iterable\n",
    "        Containing the class names (folder names in the dataset)\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    : pandas.DataFrame\n",
    "    DataFrame with columns image for the file names of the images\n",
    "    and label for the integer class label.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, c in enumerate(classes):\n",
    "        # get all image path for a class\n",
    "        img_paths = glob.glob(os.path.join(root, f\"{c}/*\"))\n",
    "\n",
    "        for img_path in img_paths:\n",
    "            img_file = img_path.replace(os.path.join(root, f\"{c}/\"), '')\n",
    "            images.append(img_file)\n",
    "            labels.append(i)\n",
    "\n",
    "    return pd.DataFrame.from_dict({'image': images, 'label': labels})\n",
    "\n",
    "def  adaIN(path_shape, path_style, path_output, size=300,\n",
    "           adaIn_execution_file=adaIn_execution_file, adaIn_vgg=adaIn_vgg,\n",
    "           adaIn_decoder=adaIn_decoder, cuda_device=cuda_device):\n",
    "\n",
    "    os.makedirs(path_output, exist_ok=True)\n",
    "\n",
    "    adaIn_call = f\"CUDA_VISIBLE_DEVICES={cuda_device} \"\\\n",
    "               + f\"{adaIn_venv_interpreter} {adaIn_execution_file} \"\\\n",
    "               + (\"--content\" if os.path.isfile(path_shape) else \"--content_dir\") + f\" {path_shape} \"\\\n",
    "               + (\"--style\" if os.path.isfile(path_style) else \"--style_dir\") + f\" {path_style} \"\\\n",
    "               + f\"--content_size {size} --style_size {size} --crop \"\\\n",
    "               + f\"--output {path_output} --vgg {adaIn_vgg} --decoder {adaIn_decoder}\"\n",
    "    \n",
    "    os.system(adaIn_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 124.05it/s]\n"
     ]
    }
   ],
   "source": [
    "style_kinds = np.array([style_kind.split('/')[-1] for style_kind in glob.glob(os.path.join(styles_path, \"*\"))])\n",
    "style_paths = glob.glob(os.path.join(styles_path, \"*\", \"*\"))\n",
    "\n",
    "df_test = create_files_dataFrame(root_test, classes)# TODO Test this out\n",
    "\n",
    "df_test[\"style_label\"] = len(df_test)*[-1]\n",
    "df_test[\"style_image\"] = len(df_test)*[\"\"]\n",
    "\n",
    "for l, c in enumerate(tqdm(classes)):\n",
    "    index_class = np.array(df_test[df_test.label == l].index)\n",
    "    index_class = index_class[np.random.permutation(len(index_class))]\n",
    "    index_split = np.array_split(index_class, len(style_kinds) + (-1 if c in style_kinds else 0))\n",
    "\n",
    "    style_labels = np.arange(len(style_kinds))\n",
    "    style_labels = style_labels[style_kinds != c]\n",
    "\n",
    "    for i, s in enumerate(style_kinds[style_kinds != c]):\n",
    "        df_test.loc[index_split[i],\"style_label\"] = style_labels[i]\n",
    "\n",
    "        style_examples = [s_e.split('/')[-1] for s_e in glob.glob(os.path.join(styles_path, s, \"*\")) ]\n",
    "\n",
    "        index_examples = np.array_split(index_split[i], len(style_examples))\n",
    "        for j, s_e in enumerate(style_examples):\n",
    "            df_test.loc[index_examples[j],\"style_image\"] = s_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:26<00:00,  4.33s/it]\n",
      "100%|██████████| 20/20 [01:13<00:00,  3.69s/it]\n",
      "100%|██████████| 20/20 [01:07<00:00,  3.36s/it]\n",
      "100%|██████████| 20/20 [01:10<00:00,  3.55s/it]\n",
      "100%|██████████| 20/20 [01:16<00:00,  3.82s/it]\n",
      "100%|██████████| 20/20 [01:08<00:00,  3.42s/it]\n",
      "100%|██████████| 20/20 [01:08<00:00,  3.40s/it]\n",
      "100%|██████████| 20/20 [01:08<00:00,  3.42s/it]\n",
      "100%|██████████| 20/20 [01:25<00:00,  4.25s/it]\n",
      "100%|██████████| 20/20 [01:08<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "for l, c in enumerate(classes):\n",
    "    for s_path in tqdm(style_paths):\n",
    "        s_e = s_path.split('/')[-1]\n",
    "        df_shape_style = df_test.query(f\"label == {l} & style_image == '{s_e}'\")\n",
    "        images = df_shape_style[\"image\"].values\n",
    "        if len(images) > 0:\n",
    "            style_label = df_shape_style[\"style_label\"].values[0]\n",
    "            out_path = os.path.join(output_path, c, style_kinds[style_label])\n",
    "\n",
    "            image_loader(s_path).save(os.path.join(tmp_style, s_path.split('/')[-1]))\n",
    "            \n",
    "            for img in images:\n",
    "                img_path = os.path.join(root_test, c, img)\n",
    "                image_loader(img_path).save(os.path.join(tmp_shape, img))\n",
    "            \n",
    "            adaIN(path_shape=tmp_shape, path_style=tmp_style, path_output=out_path, cuda_device=cuda_device)\n",
    "\n",
    "            tmp_files = glob.glob(os.path.join(tmp_shape, \"*\"))\n",
    "            tmp_files.extend(glob.glob(os.path.join(tmp_style, \"*\")))\n",
    "\n",
    "            for f in tmp_files:\n",
    "                os.remove(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
