{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import util.util_validation as ut_val\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from networks.resnet_big import model_dict\n",
    "\n",
    "seaborn.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\"CE_baseline\": [\"./save/SupCE/animals10/SupCE_animals10_resnet18_lr_0.125_decay_0.0001_bsz_26_trial_0_baseline_cosine/models/ckpt_epoch_500.pth\", None],\n",
    "               \"CE_diffAug\": [\"./save/SupCE/animals10_diff_-1+4000/SupCE_animals10_diff_-1+4000_resnet18_lr_0.125_decay_0.0001_bsz_26_trial_0_diffAug_cosine/models/last.pth\", None],\n",
    "               \"CE_diffAugAllAug\": [\"./save/SupCE/animals10_diff_-1+4000/SupCE_animals10_diff_-1+4000_resnet18_lr_0.125_decay_0.0001_bsz_26_trial_0_diffAugAllAug_cosine/models/last.pth\", None],\n",
    "               \"SupCon_baseline\": [\"./save/SupCon/animals10_diff_-1/SupCon_animals10_diff_-1_resnet18_lr_0.125_decay_0.0001_bsz_26_temp_0.1_trial_0_try3_cosine/models/last.pth\", \"\"],\n",
    "               \"SupCon_diffCSameSAug\": [\"./save/SupCon/animals10_diff_-1+4000/SupCon_animals10_diff_-1+4000_resnet18_lr_0.125_decay_0.0001_bsz_26_temp_0.1_trial_0_colorAugSameShapeAug_cosine/models/last.pth\", \"\"],\n",
    "               \"SupConHybrid_diffColorAug\": [\"./save/SupCon/animals10_diff_-1+4000/SupConHybrid_animals10_diff_-1+4000_resnet18_lr_0.125_decay_0.0001_bsz_26_temp_0.1_trial_0_colorAug_cosine/models/last.pth\", \"\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = 0\n",
    "\n",
    "root_model = models_dict[\"SupConHybrid_diffColorAug\"][0]\n",
    "\n",
    "root_dataset = \"./datasets/adaIN/shape_texture_conflict_animals10_many/\"\n",
    "\n",
    "path_save, path_run_md, epoch = ut_val.get_paths_to_embeddings_and_run_md(root_model)\n",
    "\n",
    "params = ut_val.read_parameters_from_run_md(path_run_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Dataloader and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=params['mean'], std=params['std'])\n",
    "val_transform = transforms.Compose([transforms.Resize(params['size']), transforms.CenterCrop(params['size']), transforms.ToTensor(), normalize])\n",
    "\n",
    "conflict_dataset = ut_val.shapeTextureConflictDataset(root_dataset, val_transform)\n",
    "classes = conflict_dataset.classes\n",
    "\n",
    "conflict_dataloader = torch.utils.data.DataLoader(conflict_dataset, batch_size=params['batch_size'],\n",
    "                                                  shuffle=False, num_workers=16, pin_memory=True)\n",
    "\n",
    "model = ut_val.set_model(root_model, params, len(classes), cuda_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 897/897 [04:42<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "_, embedding_size = model_dict[params['model']]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "embedding = np.array([])\n",
    "shape_labels = np.array([], dtype=int)\n",
    "texture_labels = np.array([], dtype=int)\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(conflict_dataloader):\n",
    "        images = images.cuda(device=cuda_device, non_blocking=True)\n",
    "\n",
    "        features = model.encoder(images)\n",
    "\n",
    "        embedding = np.append(embedding, features.cpu().numpy())\n",
    "        shape_labels = np.append(shape_labels, labels[0].numpy())\n",
    "        texture_labels = np.append(texture_labels, labels[1].numpy())\n",
    "\n",
    "embedding = embedding.reshape(-1, embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_texture_name_list = [path.replace(\".jpg\", '').split('/')[-3:] for path in conflict_dataset.paths]\n",
    "shapeName_textureName_list = [(s+'/'+n.split('_stylized_')[0], t+'/'+n.split('_stylized_')[1]) for s,t,n in shape_texture_name_list]\n",
    "\n",
    "shape_pairs = []\n",
    "shape_array = np.array([sN for sN,_ in shapeName_textureName_list])\n",
    "for sN in set(shape_array):\n",
    "    shape_indices = np.where(shape_array == sN)[0]\n",
    "    shape_pairs.append(shape_indices)\n",
    "\n",
    "texture_pairs = []\n",
    "texture_array = np.array([tN for _,tN in shapeName_textureName_list])\n",
    "for tN in set(texture_array):\n",
    "    texture_indices = np.where(texture_array == tN)[0]\n",
    "    texture_pairs.append(texture_indices)\n",
    "\n",
    "shape_pair_A = np.concatenate([np.tile(shape_pairs[i], reps=len(shape_pairs[i])-1) for i in range(len(shape_pairs))])\n",
    "shape_pair_B = np.concatenate([np.concatenate([np.roll(shape_pairs[i], shift=j) for j in range(1,len(shape_pairs[i]))]) for i in range(len(shape_pairs))])\n",
    "\n",
    "texture_pair_A = np.concatenate([np.tile(texture_pairs[i], reps=len(texture_pairs[i])-1) for i in range(len(texture_pairs))])\n",
    "texture_pair_B = np.concatenate([np.concatenate([np.roll(texture_pairs[i], shift=j) for j in range(1,len(texture_pairs[i]))]) for i in range(len(texture_pairs))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlation_score(embedding_A, embedding_B):\n",
    "    A = torch.tensor(embedding_A)\n",
    "    B = torch.tensor(embedding_B)\n",
    "\n",
    "    A_dm = A - A.mean(dim=0)\n",
    "    B_dm = B - B.mean(dim=0)\n",
    "\n",
    "    correlation = (A_dm.T * B_dm.T).sum(dim=1) / ((A_dm.T * A_dm.T).sum(dim=1) * (B_dm.T * B_dm.T).sum(dim=1)).sqrt()\n",
    "    correlation = torch.nan_to_num(correlation, nan=0.0)\n",
    "\n",
    "    return correlation.mean().item()\n",
    "\n",
    "def estimate_dims(correlation_scores, embedding_size):\n",
    "    scores = np.array(np.concatenate((correlation_scores, [1.0])))\n",
    "\n",
    "    m = np.max(scores)\n",
    "    e = np.exp(scores-m)\n",
    "    softmaxed = e / np.sum(e)\n",
    "\n",
    "    dim = embedding_size\n",
    "    dims = [int(s*dim) for s in softmaxed]\n",
    "    dims[-1] = dim - sum(dims[:-1])\n",
    "\n",
    "    return dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105, 161, 246]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_score_shape = compute_correlation_score(embedding[shape_pair_A], embedding[shape_pair_B])\n",
    "corr_score_texture = compute_correlation_score(embedding[texture_pair_A], embedding[texture_pair_B])\n",
    "\n",
    "dims = estimate_dims([corr_score_shape, corr_score_texture], embedding_size)\n",
    "dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CE_baseline: [93, 179, 240]\n",
    "- CE_diffAug: [90, 184, 238]\n",
    "- CE_diffAugAllAug: [96, 173, 243]\n",
    "- SupCon_baseline: [102, 159, 251]\n",
    "- SupCon_diffCSameSAug: [104, 158, 250]\n",
    "- SupConHybrid_diffColorAug: [105, 161, 246]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
